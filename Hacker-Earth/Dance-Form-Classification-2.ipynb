{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\n\nbalancer = A.Compose([\n    A.RandomScale(scale_limit=0.1,p=0.5),\n    A.RandomCrop(height=400,width=400,p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.RGBShift(p=0.5),\n    A.RandomBrightness(p=0.5),\n    A.RandomContrast(p=0.5)\n])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pandas import DataFrame\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_df = pd.read_csv('../input/identify-the-dance-form/dataset/train.csv')\n\ndance2idx = {dance:i for i,dance in enumerate(set( train_df.values[:,1] ))}\nidx2dance = {i:dance for dance,i in dance2idx.items()}\n\nprint(dance2idx)\nprint(idx2dance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.subplot(1,2,1)\n\ndances,dance_counts = np.unique(train_df.values[:,1],return_counts=True)\npd.DataFrame({\n    'train':dance_counts},\n    index=dances\n).plot.bar()\nplt.show()\n\nplt.subplot(1,2,1)\ndances,dance_counts = np.unique(train_df.values[:,1],return_counts=True)\nplt.pie(dance_counts,\n        labels=dances,\n       autopct='%0.1f%%')\nplt.title('Proportion of each observed category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport numpy as np\nimport random\n\ndef load_data(base_path,dance2idx):\n    data = {file:dance2idx[category] for file,category in train_df.values}\n    \n    X = []\n    y = []\n    for filename,category in tqdm(data.items()):\n        \n        file_path = base_path+filename\n        image = load_img(file_path,target_size=(400,400))\n        image = img_to_array(image,dtype='uint8')\n        \n        X.append(image)\n        y.append(category)\n        \n                \n    \n    for filename,category in tqdm(data.items()):\n        \n        if category != dance2idx['manipuri']:\n            continue\n        \n        if(y.count(dance2idx['manipuri'])>47):\n            break\n        \n        file_path = base_path+filename\n        image = load_img(file_path,target_size=(500,500))\n        image = img_to_array(image,dtype='uint8')\n        image = balancer(image=image.copy())['image']\n        X.append(image)\n        y.append(category)\n    \n    return X,y\n\n\n    \n\n\ndef define_model(lr=0.001, input_shape=(299,299,3)):\n    \n    base_model = InceptionV3(include_top=False, weights='imagenet',input_shape=input_shape)\n\n    inp = base_model.layers[-1].output\n    inp = layers.Flatten()(inp)\n    inp = layers.Dropout(0.5)(inp)\n    inp = layers.Dense(1024,activation='relu',kernel_initializer='glorot_normal')(inp)\n    inp = layers.Dropout(0.5)(inp)\n    inp = layers.Dense(512,activation='relu',kernel_initializer='glorot_normal')(inp)\n    output = layers.Dense(8,activation='softmax')(inp)\n\n    model = Model(inputs=base_model.inputs, outputs=output)\n    \n    opt = Adam(lr=lr)\n    model.compile(loss='sparse_categorical_crossentropy' , optimizer=opt,metrics=['acc'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\nimport random\n\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s / r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser\n\naugmenter1 = A.Compose([\n    A.RandomScale(scale_limit=0.1,p=0.5),\n    A.RandomCrop(height=299,width=299,p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.RGBShift(p=0.5),\n    A.RandomBrightness(p=0.5),\n    A.RandomContrast(p=0.5),\n    A.ISONoise(p=0.5),\n    A.GaussNoise(p=0.5),\n    A.IAAAdditiveGaussianNoise(0.5),\n    A.GaussianBlur(p=0.5),\n    A.ChannelShuffle(p=0.5),\n    A.CoarseDropout(max_holes=5,max_height=40,max_width=40, min_holes=1, min_height=20,fill_value=255, min_width=20, p=0.5)\n])\n\naugmenter2 = A.Compose([\n    A.RandomScale(scale_limit=0.1,p=0.5),\n    A.RandomCrop(height=299,width=299,p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.CoarseDropout(max_holes=5,max_height=40,max_width=40, min_holes=1, min_height=20,fill_value=255, min_width=20, p=0.5)\n])\n\ntesting_aug = A.Compose([\n#     A.RandomScale(scale_limit=0.1,p=1.0),\n    A.CenterCrop(height=224,width=224,p=1.0),\n#     A.RandomCrop(height=224,width=224,p=1.0)\n])\n\ndef define_generator(x,y,batch_size=32,augmenter=None,pixel=True):\n    while True:\n        \n        combine = list(zip(x,y))\n        random.shuffle(combine)\n        x,y = zip(*combine)\n        \n        if pixel==True:\n            eraser = get_random_eraser(p=0.9,pixel_level=True)\n        else:\n            eraser = get_random_eraser(p=0.5,pixel_level=True)\n            \n        \n        n_batchs = len(x) // batch_size\n#         print('\\n',n_batchs)\n        for i in range(n_batchs):\n            x_batch = x[i*batch_size:(i+1)*batch_size]\n            y_batch = y[i*batch_size:(i+1)*batch_size]\n            \n            if augmenter is not None:\n                x_batch = [augmenter(image=image.copy())[\"image\"] for image in x_batch]\n            \n            \n            x_batch = [preprocess_input(eraser(image)) for image in x_batch]    \n            x_batch = np.array(x_batch,dtype=x_batch[0].dtype)\n            y_batch = np.array(y_batch)\n\n            yield x_batch,y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = \"../input/identify-the-dance-form/dataset/train/\"\ntrainX,trainY = load_data(base_path,dance2idx)\n\ncombine = list(zip(trainX,trainY))\nrandom.shuffle(combine)\ntrainX,trainY = zip(*combine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = define_model(lr=0.00005)\nbatch_size = 16\nn_batchs = len(trainX)//batch_size\n\ngenerator = define_generator(trainX,trainY,batch_size=16,augmenter=augmenter1,pixel=False)\nmodel.fit_generator(generator, epochs=100, steps_per_epoch=n_batchs, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"generator = define_generator(trainX,trainY,batch_size=16,augmenter=augmenter1,pixel=False)\nmodel.fit_generator(generator, epochs=100, steps_per_epoch=n_batchs, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/identify-the-dance-form/dataset/test.csv\")\nbase_path = \"../input/identify-the-dance-form/dataset/test/\"\ntestX = []\n\nfor file in test_df.values[:,0]:\n    file_path = base_path+file\n\n    image = load_img(file_path,target_size=(299,299))\n    image = img_to_array(image,dtype='uint8')\n#     image = testing_aug(image=image)['image']\n    image = preprocess_input(image)\n    \n\n    testX.append(image)\n    \ntestX = np.array(testX,dtype=testX[0].dtype)\nprint(testX.shape)\n\npred = model.predict(testX)\n\npred = [idx2dance[np.argmax(idx)] for idx in pred]\n\ndf = {\"Image\":test_df.values[:,0] , \"target\":pred}\n\nprint(len(pred))\nprint(test_df.values[:,0].shape)\n\ndf = pd.DataFrame(df)\ndf.to_csv('submission5.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}